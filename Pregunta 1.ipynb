{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3 - Aplicaciones de Redes Neuronales </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Modelos Generativos profundos: VAE (*Variational Autoencoder*) y GAN (*Generative Adversarial Network*).\n",
    "* Arquitectura encoder-decoder y mecanismo de antención.\n",
    "* Desafío en donde se aplique todo lo aprendido.\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: -\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF395-I-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Modelos Generativos  \n",
    "[2.](#segundo) *Question-Answering*  \n",
    "[3.](#tercer) Challenge (*Object Counting*)\n",
    "\n",
    "*Nota: Para esta actividad, al igual que anteriores, si es que no se cuenta con GPU se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Modelos Generativos\n",
    "\n",
    "Las redes neuronales hoy en día han sido aplicados a muchos problemas, de los cuales algunos son necesarios tener un modelo generativo el cual pueda artificialmente sintetizar nuevos ejemplos que sean similares a los originales, éste tipo de aprendizaje se llama **Unsupervised Learning**. Existen diferentes *approaches* para ésto, de los cuales solo veremos 2.\n",
    "\n",
    "Vamos a trabajar con los datos anteriormente trabajos de MNIST.\n",
    "\n",
    "```python\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "img_rows, img_cols,channel = X_train.shape[1:]\n",
    "```\n",
    "\n",
    "\n",
    "### 1.1 *Variational Autoencoder* (VAE) [[1]](#refs)\n",
    "\n",
    "Los VAE son una variación a la arquitectura que ya vimos (autoencoder) en donde la codificación y decodificación están conectadas a través de un enfoque bayesiano en donde la codificación aprende los parámetros de alguna distribución de variables latentes de los datos y en donde el decodificador muestrea de ésta distribución de variables latentes para poder generar nuevos datos artificiales $\\hat{x}$. Dicho de otra palabras es un autoencoder que aprende el modelo de las variables latentes de los datos.\n",
    "\n",
    "\n",
    "El enfoque optimizador de los parámetros de la red neuronal $\\theta$ es que minimiza la reconstrucción de los datos (al igual que un autoencoder tradicional), en base a alguna medicicón de error (*mse* por ejemplo) agregando una regularización que se impone para que la distribución aprendida de las variables latentes sea de alguna distribución deseada *a priori*.  \n",
    "\n",
    "$$ Min \\ L(q_{\\theta}(x\\mid z),x) + KL( q_{\\theta}(z\\mid x) \\mid \\mid p_{\\theta}(z))$$\n",
    "\n",
    "Con $L$ la función de pérdida de reconstrucción, $KL$ la *KL Divergence* [[5]](#refs), $q_{\\hat{\\theta}}(x\\mid z)$ la recontrucción aleatoria de los datos a través de las variables latentes $z$ y  $p_{\\theta}(z)$ una distribución *a priori*. \n",
    "\n",
    "<img src=\"https://i.imgur.com/ZN6MyTx.png\" title=\"VAE\" width=\"60%\" />\n",
    "\n",
    "> a) Defina la sección del *encoder* del VAE como el que se muestra en el código, de 3 bloque convolucionales y una bloque *fully conected*, con una distribución Normal multivariada de 2 componentes para las variables latentes. Describa la arquitectura utilizada para el *encoder*.\n",
    "\n",
    "```python\n",
    "# input image dimensions\n",
    "original_img_size = (img_rows, img_cols,channel)\n",
    "# number of convolutional filters to use\n",
    "filters = 32\n",
    "# convolution kernel size\n",
    "num_conv = 3\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "from keras.layers import Input,Conv2D,Flatten,Dense,MaxPool2D\n",
    "from keras.models import Model\n",
    "## Encoder\n",
    "x = Input(shape=original_img_size)\n",
    "conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n",
    "conv_2 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(conv_1)\n",
    "conv_3 = Conv2D(filters*2, kernel_size=num_conv, padding='same', activation='relu', strides=2)(conv_2)\n",
    "flat = Flatten()(conv_3)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "z_mean = Dense(latent_dim,activation='linear')(hidden)\n",
    "z_log_var = Dense(latent_dim,activation='linear')(hidden)\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "```\n",
    "\n",
    "> b) Defina la sección del *decoder* del VAE como el que se muestra en el código, una tanda *fully conected* y con 3 bloque de la operación inversa a una convolución (**Convolución transpuesta** [[2]](#refs)), comente cómo ésta trabaja y los parámetros de stride como funcionan. Además se *setea* la distribución de las variables latentes como una distribución Normal multivariada de 2 componentes.\n",
    "\n",
    "```python\n",
    "from keras.layers import Reshape,Conv2DTranspose,Activation\n",
    "## Decoder\n",
    "shape_before_flattening = K.int_shape(conv_3)[1:]\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(np.prod(shape_before_flattening), activation='relu')\n",
    "decoder_reshape = Reshape(shape_before_flattening)\n",
    "decoder_deconv_1 = Conv2DTranspose(filters,kernel_size=num_conv, padding='same',strides=2,activation='relu')\n",
    "decoder_deconv_2 = Conv2DTranspose(filters,kernel_size=num_conv,padding='same', activation='relu')\n",
    "decoder_mean_squash = Conv2DTranspose(channel, kernel_size=num_conv,padding='same', activation='sigmoid')\n",
    "```\n",
    "\n",
    "> c) Defina la sección que conecta a estas dos partes a través de un *sampleo* implicito ($g = \\mu_{z^{(i)}} + \\sigma_{z^{(i)}}\\cdot \\epsilon$), ésto es lo que lo hace que sea un enfoque probabilistico/bayesiano. Describa el modelo completo.\n",
    "\n",
    "```python\n",
    "def sampling(args):\n",
    "    epsilon_std = 1.0\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "from keras.layers import Lambda\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded =  decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "x_decoded_relu = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "vae.summary()\n",
    "```\n",
    "\n",
    "> d) Como la función objetivo es *customizada* deberemos definirla y poner una distribución a *priori* sobre las variables latentes, en este caso se tendrá como media un vector de ceros y la matriz de covarianza la matriz identidad $p_{\\theta}(z) \\sim N (\\vec{0},I)$. Elija la función de pérdida para la reconstrucción. Comente porqué la *KL Divergence* podría funcionar como regularizador del criterio de entrenamiento obtenido.\n",
    "\n",
    "```python\n",
    "from keras import backend as K\n",
    "# Compute VAE loss\n",
    "#choised_loss =  keras.metrics.binary_crossentropy(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "#choised_loss =  keras.metrics.mean_squared_error(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "reconstruction_loss = img_rows * img_cols * channel* choised_loss\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.summary()\n",
    "```\n",
    "\n",
    "> e) Entrene el modelo definido con los datos de MNIST entre 10 a 15 *epochs* con el optimizador de *RMSprop* y tamaño de batch el que estime conveniente.\n",
    "\n",
    "```python\n",
    "batch_size = ...\n",
    "epochs =  [10,15]\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.fit(X_train,epochs=epochs, batch_size=batch_size,validation_data=(X_test, None))\n",
    "```\n",
    "\n",
    "> f) Visualice la representación codificada $z$ (variables latentes) de los datos en base a su media $\\mu_{z^{(i)}}$. Además genere un histograma de la media y la varianza $\\sigma_{z^{(i)}}^2$ de las dos componentes. Comente\n",
    "\n",
    "```python\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(X_test, batch_size=batch_size)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "encoder_log_var = Model(x,z_log_var)\n",
    "#histogram\n",
    "```\n",
    "\n",
    "> g) Genere nuevos datos artificialmente a través del espacio de las variables latentes. Para esto deberá generar puntos linealmente separados por debajo de la distribución Normal. Comente qué significada cada eje en la imagen ¿qué sucede más allá en el espacio del 90% confianza de las variables latentes? ¿Qué objetos se generan?\n",
    "\n",
    "```python\n",
    "#GENERATOR\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_hid_decoded = decoder_hid(decoder_input)\n",
    "_up_decoded = decoder_upsample(_hid_decoded)\n",
    "_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n",
    "_x_decoded_relu = decoder_deconv_2(_deconv_1_decoded)\n",
    "_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n",
    "generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "##PLOT\n",
    "n = 30  # figure with 15x15 images \n",
    "image_size = img_cols\n",
    "figure = np.zeros((image_size * n, image_size * n))\n",
    "from scipy.stats import norm\n",
    "#metodo de la transformada inversa\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])            \n",
    "        x_decoded = generator.predict(z_sample,batch_size=batch_size)\n",
    "        figure[i * image_size: (i + 1) * image_size,\n",
    "               j * image_size: (j + 1) * image_size] = x_decoded[0][:,:,0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure,cmap='gnuplot2')\n",
    "pos = np.arange(image_size/2,image_size*n,image_size)\n",
    "plt.yticks(pos,np.round(grid_y,1))\n",
    "plt.xticks(pos,np.round(grid_x,1))\n",
    "plt.show()\n",
    "#en los extremos del intervalo de confianza\n",
    "grid = norm.ppf(np.linspace(0.000005, 0.999995, n))\n",
    "```\n",
    "\n",
    "> h) ¿Qué pasa al cambiar la distribución latente de los datos $z$? Comente sobre alguna distribución elegida diferente a la Normal y muestre sobre el cómo debiera ser implementada.\n",
    "\n",
    "> i) Comente sobre si mejora o empeora el desempeño al aumentar la dimensionalidad de las variables latentes $z$, explique.\n",
    "\n",
    "> j) Vea qué sucede al cambiar algún aspectro estructural de la red (en su arquitectura). Recuerde que la estructura del *decoder* debe ser análoga a la del *encoder.  \n",
    "\n",
    "### 1.2 *Generative Adversarial Networks* (GAN) [[4]](#refs)\n",
    "\n",
    "\n",
    "Las GAN son un enfoque distinto de modelo generativo. A pesar de que tiene dos redes conectadas, las tareas que realiza cada una de ella son distintas. Se trata de un modelo adversario en que una red *compite* con la otra. Por un lado se tiene la red discriminadora $D$ que intenta disernir si un dato proviene de los datos reales o fue un dato generado artificialmente. Por otro lado se tiene la red generadora $G$ que intenta generar datos artificialmente de manera que la red discriminadora se confunda, es decir, sea lo más similar a los datos reales. \n",
    "\n",
    "<img src=\"https://oshearesearch.com/wp-content/uploads/2016/07/mnist_gan.png\" title=\"VAE\" width=\"60%\" />\n",
    "\n",
    "\n",
    "El enfoque optimizador de los parámetros de la red neuronal es para $D$ el de maximizar la probabilidad de los datos que provienen de la distribución original minimizando la probabilidad de los datos que provienen del modelo generativo. Mientras que para $G$ es el de maximizzar la probabilidad de que $D$ asigne un dato de $G$ como real, o bien, minimizar la probabilidad de que $D$ asigne un dato de $G$ como corrupto.\n",
    "\n",
    "$$\n",
    "min_G \\ max_G = E_{x\\sim p_{data}(x) }[logD(x)] + E_{z\\sim p_z(z)}[log(1-D(G(z))]\n",
    "$$\n",
    "\n",
    "Ésto tiene un óptimo teórico que es cuando $p_g = p_{data}$, es decir, cuando el *generador* $G$ logra imitar la distribución de probabilidad de los datos.\n",
    "\n",
    "\n",
    "\n",
    "> a) Defina al *discriminador* de la GAN como el que se muestra en el código, de 3 bloque convolucionales y una tanda *fully conected*, con los Dropout para evitar *overfitting*. Describa la arquitectura utilizada y cuál es la función de activación seleccionada.\n",
    "\n",
    "```python\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import LeakyReLU,Conv2D,Dropout,Flatten,Dense\n",
    "## Discriminator\n",
    "D = Sequential()\n",
    "depth = 64\n",
    "dropout = 0.4\n",
    "input_shape = (img_rows, img_cols, channel)\n",
    "D.add(Conv2D(depth*1, (5,5), strides=2, input_shape=input_shape,padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Conv2D(depth*2, (5,5), strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Conv2D(depth*4, (5,5), strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Flatten())\n",
    "D.add(Dense(1024,activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dense(1,activation='sigmoid'))\n",
    "D.summary()\n",
    "```\n",
    "\n",
    "> b) Defina al *generador* de la GAN como el que se muestra en el código, con una tanda *fully conected* y 3 bloque convolucionales transpuesta además de agregar *BatchNormalization* entre ellas para tener un aprendizaje más estable. Describa la arquitectura utilizada (siendo del tipo *fully convolutional* puesto que la salida es un arreglo n-dimensional) y el porqué la función de activación de la salida es *sigmoidal*.\n",
    "\n",
    "```python\n",
    "from keras.layers import BatchNormalization,Reshape,UpSampling2D,Conv2DTranspose,Activation\n",
    "## Generator\n",
    "G = Sequential()\n",
    "dim = 14\n",
    "input_dim= 2 #para que sea similar al vAE\n",
    "G.add(Dense(128, input_dim=input_dim))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Dense(dim*dim*depth))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Reshape((dim, dim, depth)))\n",
    "G.add(Conv2DTranspose(depth/2, (3,3), padding='same',strides=(2,2)))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Conv2DTranspose(depth/2, (3,3), padding='same'))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Conv2DTranspose(channel, (3,3), padding='same')) \n",
    "G.add(Activation('sigmoid')) \n",
    "G.summary()\n",
    "```\n",
    "\n",
    "> c) Conecte los modelos a través del enfoque adversario, será necesario definir dos modelos debido a que el entrenamiento es iterativo, primero se entrena el discriminador el generador fijo, luego se entrena el generador con el discriminador fijo y así. \n",
    "\n",
    "```python\n",
    "from keras.optimizers import RMSprop\n",
    "## Discriminator model (police)\n",
    "optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "DM = Sequential()\n",
    "DM.add(D)\n",
    "DM.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "## Adversarial model (Generator->Discriminator)\n",
    "D.trainable=False #set the discriminator freeze  (fixed params)\n",
    "optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "AM = Sequential()\n",
    "AM.add(G)\n",
    "AM.add(D)\n",
    "AM.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "> d) Entrene el modelo definido con el enfoque iterativo como se nombró, para ésto utilice la función que se presenta que lo realiza de manera manual. Grafique la pérdida *loss* de cada red (el generador y el discriminador/adversario) a través de los pasos de actualización de los pesos ¿Cómo se espera que sean estas curvas de aprendizaje?\n",
    "\n",
    "```python\n",
    "def train_on_steps(X_train,DM,AM,G,steps,batch_size):\n",
    "    history = {\"d\":[],\"g\":[]}\n",
    "    for e in range(train_steps):\n",
    "        # Make generative images\n",
    "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=batch_size),:,:,:] #sample images from real data\n",
    "        noise_gen = np.random.uniform(-1,1,size=[batch_size,input_dim]) #sample image from generated data\n",
    "        generated_images = G.predict(noise_gen) #fake images\n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        #create labels\n",
    "        y = np.ones([2*batch_size,1])\n",
    "        y[batch_size:,:] = 0\n",
    "        d_loss  = DM.train_on_batch(X,y)\n",
    "        history[\"d\"].append(d_loss)\n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        noise_tr = np.random.uniform(-1,1,size=[batch_size,input_dim])\n",
    "        y = np.ones([batch_size, 1])\n",
    "        g_loss = AM.train_on_batch(noise_tr, y)\n",
    "        history[\"g\"].append(g_loss)\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [G loss: %f, acc: %f]\" % (log_mesg, g_loss[0], g_loss[1])\n",
    "        print(log_mesg)\n",
    "        return history\n",
    "train_steps = 5000 #or few if  you want\n",
    "hist = train_on_steps(X_train,DM,AM,G,train_steps,64)\n",
    "```\n",
    "\n",
    "> e) Genere nuevos datos artificialmente a través del modelo generador *G* ya entrenado, para esto inicialice aleatoriamente el espacio oculto de dimensiones del generador a través de una distribución Uniforme entre -1 y 1, al igual como fue entrenado. Comente sobre las imágenes generadas y compare con lo realizado con el VAE, en temas de calidad visual y en tiempos de ejecución.\n",
    "\n",
    "```python\n",
    "N = 10\n",
    "noise = np.random.uniform(-1.0, 1.0, size=[N, input_dim]) \n",
    "images = G.predict(noise)\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(images.shape[0]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    image = images[i, :, :, :]\n",
    "    image = np.reshape(image, [img_rows, img_cols])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> f) ¿Qué le parece que resulta más crucial al momento de entrenar las GAN, saber que se tiene un buen generador e intentar mejorar el discriminador o saber que se tiene un buen discriminador e intentar mejorar el generador? en ambos casos para que el generador mejore. Experimente con una de las ideas, modifique el generador o el discriminador e intente generar mejores imágenes artificiales.\n",
    "\n",
    "> g) ¿Qué pasa al cambiar la distribución latente de los datos $z$? Comente sobre alguna distribución elegida, diferente a la Uniforme, e **implementela** entrenando completamente el modelo.\n",
    "\n",
    "> h) Comente sobre el efecto de aumentar la dimensionalidad de las variables a generar datos $z$. Compare con lo acontecido con el método generativo VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
