{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 3 - Aplicaciones de Redes Neuronales </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "* Modelos Generativos profundos: VAE (*Variational Autoencoder*) y GAN (*Generative Adversarial Network*).\n",
    "* Arquitectura encoder-decoder y mecanismo de antención.\n",
    "* Desafío en donde se aplique todo lo aprendido.\n",
    " \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: -\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea3-INF395-I-2018]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Modelos Generativos  \n",
    "[2.](#segundo) *Question-Answering*  \n",
    "[3.](#tercer) Challenge (*Object Counting*)\n",
    "\n",
    "*Nota: Para esta actividad, al igual que anteriores, si es que no se cuenta con GPU se recomienda utilizar el entorno virtual de __[Colaboratory - Google](https://colab.research.google.com/)__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"primero\"></a>\n",
    "## 1. Modelos Generativos\n",
    "\n",
    "Las redes neuronales hoy en día han sido aplicados a muchos problemas, de los cuales algunos son necesarios tener un modelo generativo el cual pueda artificialmente sintetizar nuevos ejemplos que sean similares a los originales, éste tipo de aprendizaje se llama **Unsupervised Learning**. Existen diferentes *approaches* para ésto, de los cuales solo veremos 2.\n",
    "\n",
    "Vamos a trabajar con los datos anteriormente trabajos de MNIST.\n",
    "\n",
    "```python\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "img_rows, img_cols,channel = X_train.shape[1:]\n",
    "```\n",
    "\n",
    "\n",
    "### 1.1 *Variational Autoencoder* (VAE) [[1]](#refs)\n",
    "\n",
    "Los VAE son una variación a la arquitectura que ya vimos (autoencoder) en donde la codificación y decodificación están conectadas a través de un enfoque bayesiano en donde la codificación aprende los parámetros de alguna distribución de variables latentes de los datos y en donde el decodificador muestrea de ésta distribución de variables latentes para poder generar nuevos datos artificiales $\\hat{x}$. Dicho de otra palabras es un autoencoder que aprende el modelo de las variables latentes de los datos.\n",
    "\n",
    "\n",
    "El enfoque optimizador de los parámetros de la red neuronal $\\theta$ es que minimiza la reconstrucción de los datos (al igual que un autoencoder tradicional), en base a alguna medicicón de error (*mse* por ejemplo) agregando una regularización que se impone para que la distribución aprendida de las variables latentes sea de alguna distribución deseada *a priori*.  \n",
    "\n",
    "$$ Min \\ L(q_{\\theta}(x\\mid z),x) + KL( q_{\\theta}(z\\mid x) \\mid \\mid p_{\\theta}(z))$$\n",
    "\n",
    "Con $L$ la función de pérdida de reconstrucción, $KL$ la *KL Divergence* [[5]](#refs), $q_{\\hat{\\theta}}(x\\mid z)$ la recontrucción aleatoria de los datos a través de las variables latentes $z$ y  $p_{\\theta}(z)$ una distribución *a priori*. \n",
    "\n",
    "<img src=\"https://i.imgur.com/ZN6MyTx.png\" title=\"VAE\" width=\"60%\" />\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas en imagenes:  28\n",
      "Número de columnas en imagenes:  28\n",
      "Número de canales en imagenes:  1\n"
     ]
    }
   ],
   "source": [
    "#Dataset\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import keras\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2],1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2],1))\n",
    "img_rows, img_cols,channel = X_train.shape[1:]\n",
    "print(\"Número de filas en imagenes: \",str(img_rows))\n",
    "print(\"Número de columnas en imagenes: \",str(img_cols))\n",
    "print(\"Número de canales en imagenes: \",str(channel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Defina la sección del *encoder* del VAE como el que se muestra en el código, de 3 bloque convolucionales y una bloque *fully conected*, con una distribución Normal multivariada de 2 componentes para las variables latentes. Describa la arquitectura utilizada para el *encoder*.\n",
    "\n",
    "```python\n",
    "# input image dimensions\n",
    "original_img_size = (img_rows, img_cols,channel)\n",
    "# number of convolutional filters to use\n",
    "filters = 32\n",
    "# convolution kernel size\n",
    "num_conv = 3\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "from keras.layers import Input,Conv2D,Flatten,Dense,MaxPool2D\n",
    "from keras.models import Model\n",
    "## Encoder\n",
    "x = Input(shape=original_img_size)\n",
    "conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n",
    "conv_2 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(conv_1)\n",
    "conv_3 = Conv2D(filters*2, kernel_size=num_conv, padding='same', activation='relu', strides=2)(conv_2)\n",
    "flat = Flatten()(conv_3)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "z_mean = Dense(latent_dim,activation='linear')(hidden)\n",
    "z_log_var = Dense(latent_dim,activation='linear')(hidden)\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Conv2D,Flatten,Dense,MaxPool2D\n",
    "from keras.models import Model\n",
    "\n",
    "# input image dimensions\n",
    "original_img_size = (img_rows, img_cols,channel)\n",
    "# number of convolutional filters to use\n",
    "filters = 32\n",
    "# convolution kernel size\n",
    "num_conv = 3\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "\n",
    "## Encoder\n",
    "x = Input(shape=original_img_size)\n",
    "conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n",
    "conv_2 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(conv_1)\n",
    "conv_3 = Conv2D(filters*2, kernel_size=num_conv, padding='same', activation='relu', strides=2)(conv_2)\n",
    "flat = Flatten()(conv_3)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "z_mean = Dense(latent_dim,activation='linear')(hidden)\n",
    "z_log_var = Dense(latent_dim,activation='linear')(hidden)\n",
    "# build a model to project inputs on the latent space\n",
    "encoder = Model(x, z_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "`pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1860\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[0;32m   1862\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[0;32m    675\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    958\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] El sistema no puede encontrar el archivo especificado",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1866\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1867\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f0f425b40f1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model-1A.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model-1A.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \"\"\"\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         raise OSError(\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[1;34m'`pydot` failed to call GraphViz.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;34m'Please install GraphViz (https://www.graphviz.org/) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             'and ensure that its executables are in the $PATH.')\n",
      "\u001b[1;31mOSError\u001b[0m: `pydot` failed to call GraphViz.Please install GraphViz (https://www.graphviz.org/) and ensure that its executables are in the $PATH."
     ]
    }
   ],
   "source": [
    "import os    \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from scipy.misc import imread\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "plot_model(encoder, to_file='model-1A.png', show_shapes=True)\n",
    "Image(filename='model-1A.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Defina la sección del *decoder* del VAE como el que se muestra en el código, una tanda *fully conected* y con 3 bloque de la operación inversa a una convolución (**Convolución transpuesta** [[2]](#refs)), comente cómo ésta trabaja y los parámetros de stride como funcionan. Además se *setea* la distribución de las variables latentes como una distribución Normal multivariada de 2 componentes.\n",
    "\n",
    "```python\n",
    "from keras.layers import Reshape,Conv2DTranspose,Activation\n",
    "## Decoder\n",
    "shape_before_flattening = K.int_shape(conv_3)[1:]\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(np.prod(shape_before_flattening), activation='relu')\n",
    "decoder_reshape = Reshape(shape_before_flattening)\n",
    "decoder_deconv_1 = Conv2DTranspose(filters,kernel_size=num_conv, padding='same',strides=2,activation='relu')\n",
    "decoder_deconv_2 = Conv2DTranspose(filters,kernel_size=num_conv,padding='same', activation='relu')\n",
    "decoder_mean_squash = Conv2DTranspose(channel, kernel_size=num_conv,padding='same', activation='sigmoid')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Reshape,Conv2DTranspose,Activation\n",
    "from keras import backend as K\n",
    "## Decoder\n",
    "shape_before_flattening = K.int_shape(conv_3)[1:]\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(np.prod(shape_before_flattening), activation='relu')\n",
    "decoder_reshape = Reshape(shape_before_flattening)\n",
    "decoder_deconv_1 = Conv2DTranspose(filters,kernel_size=num_conv, padding='same',strides=2,activation='relu')\n",
    "decoder_deconv_2 = Conv2DTranspose(filters,kernel_size=num_conv,padding='same', activation='relu')\n",
    "decoder_mean_squash = Conv2DTranspose(channel, kernel_size=num_conv,padding='same', activation='sigmoid') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Defina la sección que conecta a estas dos partes a través de un *sampleo* implicito ($g = \\mu_{z^{(i)}} + \\sigma_{z^{(i)}}\\cdot \\epsilon$), ésto es lo que lo hace que sea un enfoque probabilistico/bayesiano. Describa el modelo completo.\n",
    "\n",
    "```python\n",
    "def sampling(args):\n",
    "    epsilon_std = 1.0\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "from keras.layers import Lambda\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded =  decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "x_decoded_relu = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "vae.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 64)   18496       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1605760     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          384         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 12544)        1618176     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 14, 14, 64)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 32)   18464       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   9248        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 1)    289         conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,280,901\n",
      "Trainable params: 3,280,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def sampling(args):\n",
    "    epsilon_std = 1.0\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "from keras.layers import Lambda\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded =  decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "x_decoded_relu = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) Como la función objetivo es *customizada* deberemos definirla y poner una distribución a *priori* sobre las variables latentes, en este caso se tendrá como media un vector de ceros y la matriz de covarianza la matriz identidad $p_{\\theta}(z) \\sim N (\\vec{0},I)$. Elija la función de pérdida para la reconstrucción. Comente porqué la *KL Divergence* podría funcionar como regularizador del criterio de entrenamiento obtenido.\n",
    "\n",
    "```python\n",
    "from keras import backend as K\n",
    "# Compute VAE loss\n",
    "#choised_loss =  keras.metrics.binary_crossentropy(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "#choised_loss =  keras.metrics.mean_squared_error(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "reconstruction_loss = img_rows * img_cols * channel* choised_loss\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.summary()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 32)   9248        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 64)   18496       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 12544)        0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          1605760     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          384         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 12544)        1618176     dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 14, 14, 64)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 28, 28, 32)   18464       reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   9248        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 28, 28, 1)    289         conv2d_transpose_2[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 3,280,901\n",
      "Trainable params: 3,280,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "# Compute VAE loss\n",
    "#CUANDO SON DATOS ENTRE 0 Y 1, COMO EN ESTE CASO, SE USA SI O SI BINARY CROSSENTROPY\n",
    "choised_loss =  keras.metrics.binary_crossentropy(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "#choised_loss =  keras.metrics.mean_squared_error(K.flatten(x),K.flatten(x_decoded_mean_squash))\n",
    "reconstruction_loss = img_rows * img_cols * channel* choised_loss\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Entrene el modelo definido con los datos de MNIST entre 10 a 15 *epochs* con el optimizador de *RMSprop* y tamaño de batch el que estime conveniente.\n",
    "\n",
    "```python\n",
    "batch_size = ...\n",
    "epochs =  [10,15]\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.fit(X_train,epochs=epochs, batch_size=batch_size,validation_data=(X_test, None))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Output \"conv2d_transpose_3\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"conv2d_transpose_3\" during training.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 1124.3979 - val_loss: 158.8901\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 155.5325 - val_loss: 151.9110\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 150.6050 - val_loss: 148.7327\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 147.7618 - val_loss: 148.5089\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 145.8533 - val_loss: 146.6110\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 144.3625 - val_loss: 144.1136\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 143.2872 - val_loss: 143.5954\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 142.2354 - val_loss: 142.5899\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 141.7674 - val_loss: 141.6717\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 141.0781 - val_loss: 143.1441\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 140.5330 - val_loss: 141.2644\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 140.2355 - val_loss: 142.8908\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 139.7797 - val_loss: 140.9190\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 139.5160 - val_loss: 141.2622\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 139.2013 - val_loss: 141.0647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x215c2689ac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 75\n",
    "#epochs =  [10,15]\n",
    "epochs =  15\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.fit(X_train,epochs=epochs, batch_size=batch_size,validation_data=(X_test, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Visualice la representación codificada $z$ (variables latentes) de los datos en base a su media $\\mu_{z^{(i)}}$. Además genere un histograma de la media y la varianza $\\sigma_{z^{(i)}}^2$ de las dos componentes. Comente\n",
    "\n",
    "```python\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(X_test, batch_size=batch_size)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "encoder_log_var = Model(x,z_log_var)\n",
    "#histogram\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "x_test_encoded = encoder.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.title(\"Clusters\")\n",
    "plt.show()\n",
    "encoder_log_var = Model(x,z_log_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: flatten_1/Shape/_255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_31_flatten_1/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2d_1/convolution', defined at:\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-7a8be85aab10>\", line 15, in <module>\n    conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: flatten_1/Shape/_255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_31_flatten_1/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: flatten_1/Shape/_255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_31_flatten_1/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-6c9919b94e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m first_layer = K.function([encoder.layers[0].input]\n\u001b[0;32m      2\u001b[0m                         ,[encoder.layers[-1].output])\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: flatten_1/Shape/_255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_31_flatten_1/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2d_1/convolution', defined at:\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-7a8be85aab10>\", line 15, in <module>\n    conv_1 = Conv2D(filters,kernel_size=num_conv,padding='same', activation='relu')(x)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"f:\\anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: flatten_1/Shape/_255 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_31_flatten_1/Shape\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "first_layer = K.function([encoder.layers[0].input]\n",
    "                        ,[encoder.layers[-1].output])\n",
    "output = first_layer([X_test])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-67e668bbe075>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Media\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frecuencia\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x2160 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,30), sharey=True)\n",
    "a,b,c,d  = axes.flatten()\n",
    "\n",
    "a.hist(np.asarray(z_mean[0])[:], facecolor='green', alpha=0.5)\n",
    "a.set_xlabel(\"Media\", fontsize=14)\n",
    "a.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "a.set_title('Histograma Media Primera Componente', fontsize=16)\n",
    "\n",
    "\n",
    "b.hist(np.asarray(z_log_var[0])[:], facecolor='green', alpha=0.5)\n",
    "b.set_xlabel(\"Varianza\", fontsize=14)\n",
    "b.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "b.set_title('Histograma Varianza Primera Componente', fontsize=16)\n",
    "\n",
    "\n",
    "c.hist(np.asarray(z_mean[1])[:], facecolor='green', alpha=0.5)\n",
    "c.set_xlabel(\"Media\", fontsize=14)\n",
    "c.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "c.set_title('Histograma Media Segunda Componente', fontsize=16)\n",
    "\n",
    "\n",
    "d.hist(np.asarray(z_log_var[1])[:], facecolor='green', alpha=0.5)\n",
    "d.set_xlabel(\"Varianza\", fontsize=14)\n",
    "d.set_ylabel(\"Frecuencia\", fontsize=14)\n",
    "d.set_title('Histograma Varianza Segunda Componente', fontsize=16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) Genere nuevos datos artificialmente a través del espacio de las variables latentes. Para esto deberá generar puntos linealmente separados por debajo de la distribución Normal. Comente qué significada cada eje en la imagen ¿qué sucede más allá en el espacio del 90% confianza de las variables latentes? ¿Qué objetos se generan?\n",
    "\n",
    "```python\n",
    "#GENERATOR\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_hid_decoded = decoder_hid(decoder_input)\n",
    "_up_decoded = decoder_upsample(_hid_decoded)\n",
    "_reshape_decoded = decoder_reshape(_up_decoded)\n",
    "_deconv_1_decoded = decoder_deconv_1(_reshape_decoded)\n",
    "_x_decoded_relu = decoder_deconv_2(_deconv_1_decoded)\n",
    "_x_decoded_mean_squash = decoder_mean_squash(_x_decoded_relu)\n",
    "generator = Model(decoder_input, _x_decoded_mean_squash)\n",
    "##PLOT\n",
    "n = 30  # figure with 15x15 images \n",
    "image_size = img_cols\n",
    "figure = np.zeros((image_size * n, image_size * n))\n",
    "from scipy.stats import norm\n",
    "#metodo de la transformada inversa\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "for i, yi in enumerate(grid_x):\n",
    "    for j, xi in enumerate(grid_y):\n",
    "        z_sample = np.array([[xi, yi]])            \n",
    "        x_decoded = generator.predict(z_sample,batch_size=batch_size)\n",
    "        figure[i * image_size: (i + 1) * image_size,\n",
    "               j * image_size: (j + 1) * image_size] = x_decoded[0][:,:,0]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(figure,cmap='gnuplot2')\n",
    "pos = np.arange(image_size/2,image_size*n,image_size)\n",
    "plt.yticks(pos,np.round(grid_y,1))\n",
    "plt.xticks(pos,np.round(grid_x,1))\n",
    "plt.show()\n",
    "#en los extremos del intervalo de confianza\n",
    "grid = norm.ppf(np.linspace(0.000005, 0.999995, n))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> h) ¿Qué pasa al cambiar la distribución latente de los datos $z$? Comente sobre alguna distribución elegida diferente a la Normal y muestre sobre el cómo debiera ser implementada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> i) Comente sobre si mejora o empeora el desempeño al aumentar la dimensionalidad de las variables latentes $z$, explique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> j) Vea qué sucede al cambiar algún aspectro estructural de la red (en su arquitectura). Recuerde que la estructura del *decoder* debe ser análoga a la del *encoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 *Generative Adversarial Networks* (GAN) [[4]](#refs)\n",
    "\n",
    "\n",
    "Las GAN son un enfoque distinto de modelo generativo. A pesar de que tiene dos redes conectadas, las tareas que realiza cada una de ella son distintas. Se trata de un modelo adversario en que una red *compite* con la otra. Por un lado se tiene la red discriminadora $D$ que intenta disernir si un dato proviene de los datos reales o fue un dato generado artificialmente. Por otro lado se tiene la red generadora $G$ que intenta generar datos artificialmente de manera que la red discriminadora se confunda, es decir, sea lo más similar a los datos reales. \n",
    "\n",
    "<img src=\"https://oshearesearch.com/wp-content/uploads/2016/07/mnist_gan.png\" title=\"VAE\" width=\"60%\" />\n",
    "\n",
    "\n",
    "El enfoque optimizador de los parámetros de la red neuronal es para $D$ el de maximizar la probabilidad de los datos que provienen de la distribución original minimizando la probabilidad de los datos que provienen del modelo generativo. Mientras que para $G$ es el de maximizzar la probabilidad de que $D$ asigne un dato de $G$ como real, o bien, minimizar la probabilidad de que $D$ asigne un dato de $G$ como corrupto.\n",
    "\n",
    "$$\n",
    "min_G \\ max_G = E_{x\\sim p_{data}(x) }[logD(x)] + E_{z\\sim p_z(z)}[log(1-D(G(z))]\n",
    "$$\n",
    "\n",
    "Ésto tiene un óptimo teórico que es cuando $p_g = p_{data}$, es decir, cuando el *generador* $G$ logra imitar la distribución de probabilidad de los datos.\n",
    "\n",
    "\n",
    "\n",
    "> a) Defina al *discriminador* de la GAN como el que se muestra en el código, de 3 bloque convolucionales y una tanda *fully conected*, con los Dropout para evitar *overfitting*. Describa la arquitectura utilizada y cuál es la función de activación seleccionada.\n",
    "\n",
    "```python\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import LeakyReLU,Conv2D,Dropout,Flatten,Dense\n",
    "## Discriminator\n",
    "D = Sequential()\n",
    "depth = 64\n",
    "dropout = 0.4\n",
    "input_shape = (img_rows, img_cols, channel)\n",
    "D.add(Conv2D(depth*1, (5,5), strides=2, input_shape=input_shape,padding='same', activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Conv2D(depth*2, (5,5), strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Conv2D(depth*4, (5,5), strides=2, padding='same',activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dropout(dropout))\n",
    "D.add(Flatten())\n",
    "D.add(Dense(1024,activation=LeakyReLU(alpha=0.2)))\n",
    "D.add(Dense(1,activation='sigmoid'))\n",
    "D.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Defina al *generador* de la GAN como el que se muestra en el código, con una tanda *fully conected* y 3 bloque convolucionales transpuesta además de agregar *BatchNormalization* entre ellas para tener un aprendizaje más estable. Describa la arquitectura utilizada (siendo del tipo *fully convolutional* puesto que la salida es un arreglo n-dimensional) y el porqué la función de activación de la salida es *sigmoidal*.\n",
    "\n",
    "```python\n",
    "from keras.layers import BatchNormalization,Reshape,UpSampling2D,Conv2DTranspose,Activation\n",
    "## Generator\n",
    "G = Sequential()\n",
    "dim = 14\n",
    "input_dim= 2 #para que sea similar al vAE\n",
    "G.add(Dense(128, input_dim=input_dim))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Dense(dim*dim*depth))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Reshape((dim, dim, depth)))\n",
    "G.add(Conv2DTranspose(depth/2, (3,3), padding='same',strides=(2,2)))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Conv2DTranspose(depth/2, (3,3), padding='same'))\n",
    "G.add(BatchNormalization())\n",
    "G.add(Activation('relu'))\n",
    "G.add(Conv2DTranspose(channel, (3,3), padding='same')) \n",
    "G.add(Activation('sigmoid')) \n",
    "G.summary()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Conecte los modelos a través del enfoque adversario, será necesario definir dos modelos debido a que el entrenamiento es iterativo, primero se entrena el discriminador el generador fijo, luego se entrena el generador con el discriminador fijo y así. \n",
    "\n",
    "```python\n",
    "from keras.optimizers import RMSprop\n",
    "## Discriminator model (police)\n",
    "optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)\n",
    "DM = Sequential()\n",
    "DM.add(D)\n",
    "DM.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "## Adversarial model (Generator->Discriminator)\n",
    "D.trainable=False #set the discriminator freeze  (fixed params)\n",
    "optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)\n",
    "AM = Sequential()\n",
    "AM.add(G)\n",
    "AM.add(D)\n",
    "AM.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> d) Entrene el modelo definido con el enfoque iterativo como se nombró, para ésto utilice la función que se presenta que lo realiza de manera manual. Grafique la pérdida *loss* de cada red (el generador y el discriminador/adversario) a través de los pasos de actualización de los pesos ¿Cómo se espera que sean estas curvas de aprendizaje?\n",
    "\n",
    "```python\n",
    "def train_on_steps(X_train,DM,AM,G,steps,batch_size):\n",
    "    history = {\"d\":[],\"g\":[]}\n",
    "    for e in range(train_steps):\n",
    "        # Make generative images\n",
    "        image_batch = X_train[np.random.randint(0,X_train.shape[0],size=batch_size),:,:,:] #sample images from real data\n",
    "        noise_gen = np.random.uniform(-1,1,size=[batch_size,input_dim]) #sample image from generated data\n",
    "        generated_images = G.predict(noise_gen) #fake images\n",
    "        # Train discriminator on generated images\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        #create labels\n",
    "        y = np.ones([2*batch_size,1])\n",
    "        y[batch_size:,:] = 0\n",
    "        d_loss  = DM.train_on_batch(X,y)\n",
    "        history[\"d\"].append(d_loss)\n",
    "        # train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        noise_tr = np.random.uniform(-1,1,size=[batch_size,input_dim])\n",
    "        y = np.ones([batch_size, 1])\n",
    "        g_loss = AM.train_on_batch(noise_tr, y)\n",
    "        history[\"g\"].append(g_loss)\n",
    "        log_mesg = \"%d: [D loss: %f, acc: %f]\" % (e, d_loss[0], d_loss[1])\n",
    "        log_mesg = \"%s  [G loss: %f, acc: %f]\" % (log_mesg, g_loss[0], g_loss[1])\n",
    "        print(log_mesg)\n",
    "        return history\n",
    "train_steps = 5000 #or few if  you want\n",
    "hist = train_on_steps(X_train,DM,AM,G,train_steps,64)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> e) Genere nuevos datos artificialmente a través del modelo generador *G* ya entrenado, para esto inicialice aleatoriamente el espacio oculto de dimensiones del generador a través de una distribución Uniforme entre -1 y 1, al igual como fue entrenado. Comente sobre las imágenes generadas y compare con lo realizado con el VAE, en temas de calidad visual y en tiempos de ejecución.\n",
    "\n",
    "```python\n",
    "N = 10\n",
    "noise = np.random.uniform(-1.0, 1.0, size=[N, input_dim]) \n",
    "images = G.predict(noise)\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(images.shape[0]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    image = images[i, :, :, :]\n",
    "    image = np.reshape(image, [img_rows, img_cols])\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> f) ¿Qué le parece que resulta más crucial al momento de entrenar las GAN, saber que se tiene un buen generador e intentar mejorar el discriminador o saber que se tiene un buen discriminador e intentar mejorar el generador? en ambos casos para que el generador mejore. Experimente con una de las ideas, modifique el generador o el discriminador e intente generar mejores imágenes artificiales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) ¿Qué pasa al cambiar la distribución latente de los datos $z$? Comente sobre alguna distribución elegida, diferente a la Uniforme, e **implementela** entrenando completamente el modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> h) Comente sobre el efecto de aumentar la dimensionalidad de las variables a generar datos $z$. Compare con lo acontecido con el método generativo VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
